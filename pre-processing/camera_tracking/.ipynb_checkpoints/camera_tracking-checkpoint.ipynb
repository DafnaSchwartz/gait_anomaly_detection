{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/usr/local/lib/python2.7/site-packages')\n",
    "import cv2\n",
    "sys.path.insert(1, '/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy.io as sio\n",
    "from scipy import interpolate\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "help_message = ''' USAGE: camera_tracking.py [<video_source>] '''\n",
    "\n",
    "# VISUALIZE RESULTS\n",
    "VISUALIZE = 0\n",
    "\n",
    "# COSTANTS\n",
    "MIN_FEATURES = 800 # min number of features \n",
    "THRESH_VAL = 1 # RANSAC threshold - optimal value depends on the video (try 1->5)\n",
    "OUTLIERS_VAL = 10\n",
    "ALPHA = 1 # ALPHA = 1 -> only new values\n",
    "BETA = 1 # alto BETA -> meno sensibile a curve\n",
    "\n",
    "# Intrinsic camera parameters\n",
    "\n",
    "# RES: 576 X 720\n",
    "mtx = np.array([[ 875.8470374 ,    0.        ,  290.22010515],\n",
    "\t  [   0.        ,  618.67901671,  348.7369155 ],\n",
    "\t  [   0.        ,    0.        ,    1.        ]], dtype = float)\n",
    "invmtx = np.linalg.inv(mtx)\n",
    "dist = np.array([[ 0.21486217, -0.47784865, -0.00159837,  0.00146397, -0.17732472]], dtype = float)\n",
    "\n",
    "# Calculate optical flow and get rid of bad points\n",
    "def featureTracking(old, new, p0, **lk_params):\n",
    "\t# Calculate optical flow - KLT\n",
    "\tp1, st, err = cv2.calcOpticalFlowPyrLK(old, new, p0, None, **lk_params)\n",
    "\t# Getting rid of points for which the KLT tracking failed or those who have gone outside the frame\n",
    "\tindexCorrection = 0\n",
    "\tfor i in range(len(st)):\n",
    "\t   pt = p1[i - indexCorrection][0]\n",
    "\t   if ((st[i] == 0) or (pt[0] < 0) or (pt[1] < 0)):\n",
    "\t\t  if ((pt[0] < 0) or (pt[1] < 0)):\n",
    "\t\t\t st[i] = 0\n",
    "\t\t  p0 = np.delete(p0, (i - indexCorrection), axis = 0)\n",
    "\t\t  p1 = np.delete(p1, (i - indexCorrection), axis = 0)\n",
    "\t\t  indexCorrection += 1  \n",
    "\n",
    "\treturn p0, p1\n",
    "\n",
    "# Camera calibration + coordinates normalization \n",
    "def calibration(frame, mtx, dist):\n",
    "\th,  w = frame.shape[:2]\n",
    "\tnewcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "\t# undistort\n",
    "\tdst = cv2.undistort(frame, mtx, dist, None, newcameramtx)\n",
    "\tx,y,w,h = roi\n",
    "\tdst = dst[y:y+h, x:x+w] # crop the frame\n",
    "\n",
    "\th,  w = dst.shape[:2]\n",
    "\tcenter = (w / 2, h / 2)\n",
    "\tM = cv2.getRotationMatrix2D(center, 270, 1.0)\n",
    "\tdst = cv2.warpAffine(dst, M, (w, h))\n",
    "\n",
    "\treturn dst\n",
    "\n",
    "# Return yaw, pitch and roll in degrees\n",
    "def decomposeR(R):\n",
    "\tthx = math.atan2(R[2,1],R[2,2])\n",
    "\tthy = math.atan2(-R[2,0], math.sqrt(math.pow(R[2,1],2) + math.pow(R[2,2],2)))\n",
    "\tthz = math.atan2(R[1,0],R[0,0])\n",
    "\n",
    "\treturn math.degrees(thx), math.degrees(thy), math.degrees(thz)\n",
    "\n",
    "# Return normalized coordinates (----- NOT NEEDED ------)\n",
    "def pointNorm(p):\n",
    "\tp = cv2.convertPointsToHomogeneous(p).dot(invmtx)\n",
    "\n",
    "\treturn cv2.convertPointsFromHomogeneous(p)\n",
    "\n",
    "def checkVideoFrames(cap, n_frames): \n",
    "\ttoKeep = []\n",
    "\tfor i in range(n_frames):\n",
    "\t   ret, frame = cap.read()\n",
    "\t   frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\t   if ret == True and frame_gray.sum() < frame_gray.shape[0]*frame_gray.shape[1] * 255 * 0.9:\n",
    "\t\t  toKeep.append(i)\n",
    "\n",
    "\treturn np.array(toKeep)\n",
    "\n",
    "# Valore dei frame con problemi viene rimpiazzato con il valore del frame accettato piu' vicino    \n",
    "def postProc(n_frames, toKeep, inputz):\n",
    "\ttemp = np.zeros(n_frames)\n",
    "\ttemp[toKeep] = np.array(inputz)\n",
    "\tindex0 = np.where(temp == 0)[0]\n",
    "\tindex1 = np.where(temp != 0)[0]\n",
    "\tfor i in index0:\n",
    "\t\tidx = ((index1 - i)).min()\n",
    "\tif idx >= 0:\n",
    "\t   temp[i] = temp[idx + i]\n",
    "\telse:\n",
    "\t   idx = ((index1 - i)).max()\n",
    "\t   temp[i] = temp[idx + i]\n",
    "\t\n",
    "\treturn temp\n",
    "\n",
    "def main():\n",
    "\t# Close all existing plots\n",
    "\tplt.close(\"all\")\n",
    "\n",
    "\tif len(sys.argv[1:]) < 1: \n",
    "\t\tprint help_message\n",
    "\t\tinput_video = raw_input(\"\\nChoose video file: \")\n",
    "\telse: # input passato da riga di comando\n",
    "\t\tinput_video = sys.argv[1] \n",
    "\t# Input video\n",
    "\tcap = cv2.VideoCapture('/Users/albertolanaro/Desktop/camera_tracking/InputVideos/' + str(input_video) + '.mp4')\n",
    "\tn_frames0 = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\tvideo_info = pd.read_csv('/Users/albertolanaro/Desktop/camera_tracking/video_info/video_info_' + str(input_video) + '.txt', sep = '\\t', header = None)\n",
    "\tn_frames = int(video_info.iat[2,1])\n",
    "\n",
    "\t# Check which frames are good\n",
    "\ttoKeep = checkVideoFrames(cap, n_frames0)\n",
    "\tcounter = 0\n",
    "\t\n",
    "\t# Take first two useful frames and extract keypoints\n",
    "\t\n",
    "\tcap.set(1, toKeep[counter]);\n",
    "\tcounter += 1\n",
    "\tret, old_frame0 = cap.read()\n",
    "\told_frame0 = calibration(old_frame0, mtx, dist)\n",
    "\t\n",
    "\tcap.set(1, toKeep[counter]);\n",
    "\tcounter += 1\n",
    "\tret, old_frame1 = cap.read()\n",
    "\told_frame1 = calibration(old_frame1, mtx, dist)\n",
    "\n",
    "\t# color --> gray\n",
    "\told_gray0 = cv2.cvtColor(old_frame0, cv2.COLOR_BGR2GRAY)\n",
    "\told_gray1 = cv2.cvtColor(old_frame1, cv2.COLOR_BGR2GRAY)\n",
    "\t\n",
    "\t# Keypoints extraction - SIFT/FAST\n",
    "\tsift = cv2.xfeatures2d.SIFT_create()\n",
    "\t#fast = cv2.FastFeatureDetector_create( threshold = 20, nonmaxSuppression = True)\n",
    "\t#kp = fast.detect(old_frame0, None)\n",
    "\tkp = sift.detect(old_frame0, None) \n",
    "\tprint \"\\n\" + str(len(kp)) + \" features extracted\\n\"\n",
    "\tp0 = np.zeros((len(kp),1,2), dtype = np.float32)\n",
    "\tfor i in range(len(kp)):\n",
    "\t   p0[i,0,0] , p0[i,0,1] = kp[i].pt\n",
    "\t   \n",
    "\t# Optical flow parameters\n",
    "\t# ORIGINAL: winSize = (21,21) maxLevel = 2\n",
    "\tlk_params = dict(winSize = (21,21), maxLevel = 2, criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)) \n",
    "\t# Track features\n",
    "\tp0, p1 = featureTracking(old_gray0, old_gray1, p0, **lk_params)\n",
    "\t# Compute fundamental matrix for first 2 frames\n",
    "\tF, maskr = cv2.findFundamentalMat(p0, p1, method = cv2.FM_RANSAC, param1 = THRESH_VAL, param2 = 0.999)\n",
    "\t# Compute essential matrix for first 2 frames\n",
    "\tEr = mtx.transpose().dot(F).dot(mtx) # good for R\n",
    "\tEt, maskt = cv2.findEssentialMat(p0, p1, method = cv2.RANSAC, focal = 1, threshold = THRESH_VAL, prob = 0.999) # good for t\n",
    "\t# Recover R and t from E\n",
    "\tpoints, Rr, tr, mask = cv2.recoverPose(Er, p0, p1, focal = 1, mask = maskr)\n",
    "\tpoints, Rt, tt, mask = cv2.recoverPose(Et, p0, p1, focal = 1, mask = maskt)\n",
    "\t# Variables initialization\n",
    "\tR_f = Rr  # rotation matrix\n",
    "\tt_f = tr #tt  # translation matrix\n",
    "\t\n",
    "\tR_frpred = Rr.copy()\n",
    "\tRr_pred = Rr.copy()\n",
    "\ttr_pred = tr.copy()\n",
    "\tRalways = Rr.copy() #Â always updated\n",
    "\t\n",
    "\tR_ft = Rt.copy()\n",
    "\ttt_pred = tt.copy() # transaltion matrix of the previous frame\n",
    "\tR_ftpred = Rt.copy() # rotation matrix of the previous frame\n",
    "\tRt_pred = Rt.copy()\n",
    "\t\n",
    "\t# Decompose rotation matrix -> pitch, roll, yaw\n",
    "\tthx_old, thy_old, thz_old = decomposeR(R_f)\n",
    "\tdeltax = 0\n",
    "\tdeltay = 0\n",
    "\tdeltaz = 0\n",
    "\tthx = 0\n",
    "\tthy = 0\n",
    "\tthz = 0\n",
    "\tdeltax_fin = []\n",
    "\tdeltax_fin.append(0)\n",
    "\tdeltay_fin = []\n",
    "\tdeltay_fin.append(0)\n",
    "\tdeltaz_fin = []\n",
    "\tdeltaz_fin.append(0)\n",
    "\tthx_fin = []\n",
    "\tthx_fin.append(0)\n",
    "\tthy_fin = []\n",
    "\tthy_fin.append(0)\n",
    "\tthz_fin = []\n",
    "\tthz_fin.append(0)\n",
    "\tt_fin = []\n",
    "\tt_fin.append(t_f)\n",
    "\n",
    "\t# Update variables\n",
    "\told_gray0 = old_gray1.copy()  \n",
    "\tp0 = p1 \n",
    "\t\n",
    "\t# Do the same for all other frames   \n",
    "\twhile(counter < len(toKeep)):\n",
    "\t\tcap.set(1, toKeep[counter])\n",
    "\t\tret, frame = cap.read()\n",
    "\t\tframe = calibration(frame, mtx, dist)\n",
    "\t\tframe_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\t\t# Tracks extracted features\n",
    "\t\tp0, p1 = featureTracking(old_gray0, frame_gray, p0, **lk_params)\n",
    "\t\tF, maskr = cv2.findFundamentalMat(p0, p1, method = cv2.FM_RANSAC, param1 = THRESH_VAL, param2 = 0.999)\n",
    "\t\t# Recover essential matrix E,R and t\n",
    "\t\tEr = mtx.transpose().dot(F).dot(mtx) # good for R\n",
    "\t\tEt, maskt = cv2.findEssentialMat(p0, p1, method = cv2.RANSAC , focal = 1, threshold = THRESH_VAL, prob = 0.999) # good for t\n",
    "\t\tpoints, Rr, tr, mask = cv2.recoverPose(Er, p0, p1, focal = 1, mask = maskr)\n",
    "\t\tpoints, Rt, tt, mask = cv2.recoverPose(Et, p0, p1, focal = 1, mask = maskt)\n",
    "\t\t# Update R_f and t_f\n",
    "\t\t'''\n",
    "\t\tif ((tt[2] > BETA * tt[0]) and (tt[2] >  BETA * tt[1])):\n",
    "\t\t\tt_f = t_f - (ALPHA * R_ft.dot(tt) + (1 - ALPHA) * R_ftpred.dot(tt_pred))\n",
    "\t\t\tR_ft = Rt.dot(R_ft)\n",
    "\t\tR_f = Rr.dot(R_f) # final rotation matrix\n",
    "\t\t'''\n",
    "\t\tif ((tr[2] > BETA * tr[0]) and (tr[2] > BETA * tr[1])):\n",
    "\t\t\tt_f = t_f + (ALPHA * R_f.dot(tr) + (1 - ALPHA) * R_frpred.dot(tr_pred))\n",
    "\t\t\tR_f = Rr.dot(R_f)\n",
    "\t\tRalways = Rr.dot(Ralways)\n",
    "\t   \n",
    "\t\t# decompose rotation matrix\n",
    "\t\tthx, thy, thz = decomposeR(Ralways) #Â Ralways\n",
    "\n",
    "\t\tt_fin.append(t_f)\n",
    "\t\tthx_fin.append(thx)\n",
    "\t\tthy_fin.append(thy)\n",
    "\t\tthz_fin.append(thz)\n",
    "\t   \n",
    "\t\t# Check if I have some strange values\n",
    "\t\tif math.fabs(thx - thx_old) < OUTLIERS_VAL:\n",
    "\t\t\tdeltax = thx - thx_old\n",
    "\t\t\tdeltax_fin.append(deltax)\n",
    "\t\telse:\n",
    "\t\t\tdeltax_fin.append(deltax) # append old value\n",
    "\t\tif math.fabs(thy - thy_old) < OUTLIERS_VAL:\n",
    "\t\t\tdeltay = thy - thy_old\n",
    "\t\t\tdeltay_fin.append(deltay)\n",
    "\t\telse:\n",
    "\t\t\tdeltay_fin.append(deltay) # append old value\n",
    "\t\tif math.fabs(thz - thz_old) < OUTLIERS_VAL:\n",
    "\t\t\tdeltaz = thz - thz_old\n",
    "\t\t\tdeltaz_fin.append(deltaz)\n",
    "\t\telse:\n",
    "\t\t\tdeltaz_fin.append(deltaz) # append old value\n",
    "\n",
    "\t\t# Triggered if more keypoints needed    \n",
    "\t\tif len(p0) < MIN_FEATURES:  \n",
    "\t\t\t#kp = fast.detect(frame_gray, None)\n",
    "\t\t\tkp = sift.detect(old_gray0, None)\n",
    "\t\t\tprint \"\\n\" + str(len(kp)) + \" features extracted\\n\"\n",
    "\t\t\tp0 = np.zeros((len(kp),1,2), dtype = np.float32)\n",
    "\t\t\tfor i in range(len(kp)):\n",
    "\t\t\t\tp0[i,0,0] , p0[i,0,1] = kp[i].pt\n",
    "\t\t\tp0, p1 = featureTracking(old_gray0, frame_gray, p0, **lk_params)\n",
    "\t   \n",
    "\t\t# Visualize results if VISUALIZE is flagged\n",
    "\t\tif VISUALIZE:\n",
    "\t\t\t# Plot translation in XZ plane\n",
    "\t\t\tplt.figure(1)\n",
    "\t\t\tplt.plot(t_f[0], t_f[2],'ko')\n",
    "\t\t\tplt.xlabel('x')\n",
    "\t\t\tplt.ylabel('z')\n",
    "\t\t\tplt.title('XZ translation')\n",
    "\t\t\tplt.pause(0.001)\n",
    "\t\t\t# Plot delta roll, pitch, yaw\n",
    "\t\t\tylims = np.array([-5,5])\n",
    "\t\t\tplt.figure(2, figsize=(16,8))\n",
    "\t\t\tplt.subplot(311)\n",
    "\t\t\t#plt.ylim(ylims)\n",
    "\t\t\tplt.plot(counter, deltax, 'ko') # yaw\n",
    "\t\t\tplt.title('delta_Yaw')\n",
    "\t\t\tplt.subplot(312)\n",
    "\t\t\t#plt.ylim(ylims)\n",
    "\t\t\tplt.plot(counter, deltay, 'ko') # pitch\n",
    "\t\t\tplt.title('delta_Pitch')\n",
    "\t\t\tplt.subplot(313)\n",
    "\t\t\t#plt.ylim(ylims)\n",
    "\t\t\tplt.plot(counter, deltaz, 'ko') # roll\n",
    "\t\t\tplt.title('delta_Roll')\n",
    "\t\t\tplt.pause(0.001)\n",
    "\t\t\tcv2.imshow('Video',frame)\n",
    "\t\t\tk = cv2.waitKey(1)\n",
    "\t\t\tprint 'frame ' + str(toKeep[counter]) + ' of ' + str(n_frames)\n",
    "\t\telse: \n",
    "\t\t\tprint 'frame ' + str(toKeep[counter]) + ' of ' + str(n_frames)\n",
    "\n",
    "\t\t# Update variables\n",
    "\t\tcounter += 1\n",
    "\t\told_gray0 = frame_gray.copy()\n",
    "\t\tp0 = p1.copy()\n",
    "\n",
    "\t\tthx_old = thx\n",
    "\t\tthy_old = thy\n",
    "\t\tthz_old = thz\n",
    "\t   \n",
    "\t\tR_frpred = R_f.copy()\n",
    "\t\ttr_pred = tr.copy()\n",
    "\t\tRr_pred = Rr.copy()\n",
    "\t   \n",
    "\t\tR_ftpred = R_ft.copy()\n",
    "\t\ttt_pred = tt.copy()\n",
    "\t\tRt_pred = Rt.copy()\n",
    "\n",
    "\t# post processing\n",
    "\tdeltax_fin = postProc(n_frames, toKeep, deltax_fin)\n",
    "\tdeltay_fin = postProc(n_frames, toKeep, deltay_fin)\n",
    "\tdeltaz_fin = postProc(n_frames, toKeep, deltaz_fin)\n",
    "\tthx_fin = postProc(n_frames, toKeep, thx_fin)\n",
    "\tthy_fin = postProc(n_frames, toKeep, thy_fin)\n",
    "\tthz_fin = postProc(n_frames, toKeep, thz_fin)\n",
    "\t\n",
    "\t# save matrices\n",
    "\tsio.savemat('/Users/albertolanaro/Desktop/camera_tracking/Output/' + str(input_video) +'_deltax.mat', {'deltax':deltax_fin})\n",
    "\tsio.savemat('/Users/albertolanaro/Desktop/camera_tracking/Output/' + str(input_video) +'_deltay.mat', {'deltay':deltay_fin})\n",
    "\tsio.savemat('/Users/albertolanaro/Desktop/camera_tracking/Output/' + str(input_video) +'_deltaz.mat', {'deltaz':deltaz_fin})\n",
    "\tsio.savemat('/Users/albertolanaro/Desktop/camera_tracking/Output/' + str(input_video) + '_thx.mat', {'thx':thx_fin})\n",
    "\tsio.savemat('/Users/albertolanaro/Desktop/camera_tracking/Output/' + str(input_video) + '_thy.mat', {'thy':thy_fin})\n",
    "\tsio.savemat('/Users/albertolanaro/Desktop/camera_tracking/Output/' + str(input_video) + '_thz.mat', {'thz':thz_fin})\n",
    "\tsio.savemat('/Users/albertolanaro/Desktop/camera_tracking/Output/' + str(input_video) + '_t.mat', {'t_f':t_fin})\n",
    "\t\n",
    "\tif not(VISUALIZE):\n",
    "\t\tt_fin = np.array(t_fin)\n",
    "\t\tt_fin.flatten()\n",
    "\t\tcv2.destroyAllWindows()\n",
    "\t\tplt.figure(3)\n",
    "\t\tplt.plot(t_fin[:,0], t_fin[:,2],'ko')\n",
    "\t\tplt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
